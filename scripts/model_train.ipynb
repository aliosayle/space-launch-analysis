{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: dim_countries, Shape: (249, 2)\n",
      "Table: dim_locations, Shape: (137, 5)\n",
      "Table: dim_organisations, Shape: (56, 3)\n",
      "Table: fact_conflicts, Shape: (2686, 6)\n",
      "Table: fact_launches, Shape: (4324, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Connect to the database\n",
    "engine = create_engine('mysql+pymysql://root:@localhost/space_launch_db')\n",
    "\n",
    "# Query to get all table names in the current database\n",
    "query_tables = \"\"\"\n",
    "SELECT TABLE_NAME \n",
    "FROM information_schema.TABLES \n",
    "WHERE TABLE_SCHEMA = DATABASE()\n",
    "\"\"\"\n",
    "\n",
    "# Open a connection and execute the query to get table names\n",
    "with engine.connect() as connection:\n",
    "    result_tables = connection.execute(text(query_tables)).fetchall()\n",
    "\n",
    "# Extract table names from the result\n",
    "table_names = [row[0] for row in result_tables]\n",
    "\n",
    "# Dictionary to hold the DataFrames for each table\n",
    "dfs = {}\n",
    "\n",
    "# Loop through each table, load it into a DataFrame, and store it in the dictionary\n",
    "for table in table_names:\n",
    "    query = f\"SELECT * FROM {table}\"\n",
    "    dfs[table] = pd.read_sql(query, engine)\n",
    "\n",
    "# Now all tables are loaded into DataFrames and stored in the `dfs` dictionary\n",
    "# Example: To access a specific table's DataFrame, you can use dfs['table_name']\n",
    "# Print all table names and their corresponding DataFrame shapes\n",
    "for table, df in dfs.items():\n",
    "    print(f\"Table: {table}, Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_launches = dfs['fact_launches']\n",
    "fact_conflicts = dfs['fact_conflicts']\n",
    "dim_countries = dfs['dim_countries']\n",
    "dim_locations = dfs['dim_locations']\n",
    "dim_organisations = dfs['dim_organisations']\n",
    "fact_launches = fact_launches.merge(dim_locations, on='location_id', how='left')\n",
    "fact_launches = fact_launches.merge(dim_organisations, on='organisation_id', how='left')\n",
    "fact_launches = fact_launches.merge(dim_countries, on='country_id', how='left')\n",
    "fact_launches.drop(columns= ['organisation_id', 'location_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        date                                        detail rocket_status  \\\n",
      "0   0  2020-08-07  Falcon 9 Block 5 | Starlink V1 L9 & BlackSky  StatusActive   \n",
      "1   1  2020-08-06           Long March 2D | Gaofen-9 04 & Q-SAT  StatusActive   \n",
      "2   2  2020-08-04            Starship Prototype | 150 Meter Hop  StatusActive   \n",
      "3   3  2020-07-30  Proton-M/Briz-M | Ekspress-80 & Ekspress-103  StatusActive   \n",
      "4   4  2020-07-30                    Atlas V 541 | Perseverance  StatusActive   \n",
      "\n",
      "    price mission_status  wind_speed  humidity  temperature  \\\n",
      "0   50.00        Success     5.33923   75.4536      5.10021   \n",
      "1   29.75        Success     8.35946   51.0117      5.46586   \n",
      "2     NaN        Success    11.74800   56.7506     20.54830   \n",
      "3   65.00        Success    13.00410   69.0498     -1.34319   \n",
      "4  145.00        Success     5.58771   60.5856     18.02130   \n",
      "\n",
      "                                            location  latitude  longitude  \\\n",
      "0         LC-39A, Kennedy Space Center, Florida, USA   30.9194   -87.3141   \n",
      "1  Site 9401 (SLS-2), Jiuquan Satellite Launch Ce...   35.0000   105.0000   \n",
      "2                      Pad A, Boca Chica, Texas, USA   30.0568   -94.0983   \n",
      "3       Site 200/39, Baikonur Cosmodrome, Kazakhstan   46.0000    63.2500   \n",
      "4           SLC-41, Cape Canaveral AFS, Florida, USA   28.3940   -80.6031   \n",
      "\n",
      "   country_id organisation  isprivate        country  \n",
      "0         238       SpaceX          1  United States  \n",
      "1          47         CASC          0          China  \n",
      "2         238       SpaceX          1  United States  \n",
      "3         116    Roscosmos          0     Kazakhstan  \n",
      "4         238          ULA          1  United States  \n"
     ]
    }
   ],
   "source": [
    "print(fact_launches.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fact_launches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Success', 'Failure', 'Prelaunch Failure', 'Partial Failure'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mission_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d2/zqv2mpg17tzb0413h3b_jwb00000gn/T/ipykernel_44854/3705030629.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price'].fillna(df['price'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9040\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.11      0.19        87\n",
      "           1       0.91      0.99      0.95       778\n",
      "\n",
      "    accuracy                           0.90       865\n",
      "   macro avg       0.77      0.55      0.57       865\n",
      "weighted avg       0.88      0.90      0.87       865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "# Dropping columns that are not needed (id, detail, date, etc.)\n",
    "df.drop(columns=['id', 'detail', 'date'], inplace=True)\n",
    "\n",
    "# Handling missing values\n",
    "df['price'].fillna(df['price'].mean(), inplace=True)\n",
    "\n",
    "# Convert target variable to binary (Success = 1, Failure = 0)\n",
    "df['mission_status'] = df['mission_status'].apply(lambda x: 1 if x == 'Success' else 0)\n",
    "\n",
    "# Encoding categorical columns\n",
    "label_encoders = {}\n",
    "for col in ['rocket_status', 'location', 'organisation', 'country']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns='mission_status')\n",
    "y = df['mission_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/success_prediction_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = '../models/success_prediction_model.pkl'\n",
    "joblib.dump(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 415.9626\n",
      "R-squared: 0.9058\n",
      "Feature Importances: [0.22607448 0.03389455 0.03106727 0.03007478 0.25637455 0.12067895\n",
      " 0.11527556 0.00877004 0.15371925 0.01851118 0.00555938]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Handling missing values in the price (target variable)\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "# Cap the price at the 99th percentile to remove extreme outliers\n",
    "price_cap = df['price'].quantile(0.99)\n",
    "df['price'] = np.where(df['price'] > price_cap, price_cap, df['price'])\n",
    "\n",
    "# Apply log transformation to the price column to stabilize variance\n",
    "df['price'] = np.log1p(df['price'])\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in ['rocket_status', 'location', 'organisation', 'country']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns='price')\n",
    "y = df['price']\n",
    "\n",
    "# Normalize/scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['wind_speed', 'humidity', 'temperature', 'latitude', 'longitude']] = scaler.fit_transform(\n",
    "    X[['wind_speed', 'humidity', 'temperature', 'latitude', 'longitude']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Model Training with cross-validation\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Reverse log transformation for price\n",
    "y_test_exp = np.expm1(y_test)\n",
    "y_pred_exp = np.expm1(y_pred)\n",
    "\n",
    "# Model Evaluation\n",
    "mse = mean_squared_error(y_test_exp, y_pred_exp)\n",
    "r2 = r2_score(y_test_exp, y_pred_exp)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"Feature Importances:\", best_model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/rocket_launch_cost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_dir = '../models'\n",
    "os.makedirs(model_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "model_path = os.path.join(model_dir, 'rocket_launch_cost_model.pkl')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
